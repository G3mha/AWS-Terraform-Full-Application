# Infraestrutura AWS usando Terraform para Aplica√ß√£o CRUD em FastAPI

üá∫üá∏ Vers√£o em Ingl√™s: [clique aqui](./README.md)

## Introdu√ß√£o

Projeto desenvolvido por **Enricco Gemha** para a disciplina de **Computa√ß√£o em Nuvem** do curso de **Engenharia de Computa√ß√£o** do **Insper Instituto de Ensino e Pesquisa**.

Dado a especifica√ß√£o do projeto, foi desenvolvido um CRUD simples em Python utilizando os frameworks FastAPI e SQLAlchemy, e o banco de dados MySQL, dispon√≠vel em [Python-FastAPI-CRUD](https://github.com/G3mha/Python-FastAPI-CRUD).

A aplica√ß√£o foi hospedada na Amazon Web Services (AWS), sendo poss√≠vel criar toda a infraestrutura necess√°ria para a aplica√ß√£o utilizando somente o script Terraform dispon√≠vel neste reposit√≥rio, bem como destru√≠-la completamente.

## Subindo a infraestrutura com Terraform

Para come√ßar, √© necess√°rio ter uma conta na AWS e obter seu `access_key_id` e `secret_access_key`.

O pr√≥ximo passo √© instalar o AWS CLI, e configurar as credenciais de acesso no seu computador, para isso siga as instru√ß√µes dispon√≠veis [aqui](https://docs.aws.amazon.com/pt_br/rekognition/latest/dg/setup-awscli-sdk.html).

Em seguida, √© necess√°rio instalar o Terraform, para isso siga as instru√ß√µes dispon√≠veis [aqui](https://developer.hashicorp.com/terraform/install).

E configure o arquivo `terraform.tfvars` no `<path_to_this_project>/terraform` com as informa√ß√µes necess√°rias para a cria√ß√£o da infraestrutura. O arquivo deve ter o seguinte formato:

```terraform
db_username = "<usu√°rio>"
db_password = "<senha>"
```

**Assumindo que voc√™ esteja na ra√≠z do reposit√≥rio**, execute os seguintes comandos:

```bash
cd terraform/bucket
terraform init
terraform validate
terraform plan -out="tfplan"
terraform apply "tfplan"
```

```bash
cd ..
terraform init
terraform validate
terraform plan -out="tfplan"
terraform apply "tfplan"
```

## Testando a aplica√ß√£o

Ao final da execu√ß√£o do Terraform, ser√£o exibidos no terminal, respectivamente, o ALB DNS name e o Locust Public IPv4 DNS.

Para testar a aplica√ß√£o FastAPI, √© necess√°rio acessar o endere√ßo da ALB no navegador. Para testar a aplica√ß√£o Locust, √© necess√°rio acessar o endere√ßo do Locust no navegador.

## Destruindo a infraestrutura com Terraform

Para destruir a infraestrutura, execute os seguintes comandos:

```bash
cd terraform/bucket
aws s3 rm s3://enricco-terraform-state --recursive
terraform destroy
```

```bash
cd ..
terraform destroy
```

## Diagrama de infraestrutura

![Diagrama de infraestrutura](./docs/diagram.png)

Neste diagrama, cada cor representa uma camada de abstra√ß√£o da infraestrutura, sendo `preto` a cor referente a camada de servi√ßos AWS, ou seja, a camada de "cloud", em `roxo` a camada de rede, como o IPRouter e a VPC, em `vermelho` as camadas de seguran√ßa, representadas pelos Security Groups, em `verde` as camadas de subnets, p√∫blica e privada, em `azul` a camada de monitoramento, representada pelo CloudWatch, e em `laranja` a camada de aplica√ß√£o, representada pelas inst√¢ncias EC2, o ALB e o banco de dados RDS, bem como a pr√≥pria aplica√ß√£o CRUD que √© vis√≠vel ao usu√°rio. A World Wide Web √© representada por um c√≠rculo em `azul`. As setas representam a comunica√ß√£o entre os servi√ßos.

## Documenta√ß√£o da aplica√ß√£o

Servi√ßos utilizados:

### VPC (Virtual Private Cloud)

A Virtual Private Cloud (VPC) foi criada para isolar a infraestrutura. A VPC possui CIDR 172.31.0.0/16. Assim, geramos 2 subnets privadas e 2 subnets p√∫blicas, sendo:

- Subnet privada 1:
  - CIDR: 172.31.0.0/26
  - Availability Zone: `eu-west-1a`;

- Subnet privada 2:
  - CIDR: 172.31.0.64/26
  - Availability Zone: `eu-west-1b`;

- Subnet p√∫blica 1:
  - CIDR: 172.31.0.128/26
  - Availability Zone: `eu-west-1a`;

- Subnet p√∫blica 2:
  - CIDR: 172.31.0.192/26
  - Availability Zone: `eu-west-1b`;

### Security Groups

Para garantir a seguran√ßa da aplica√ß√£o, foram criados quatro Security Groups, permitindo somente os servi√ßos necess√°rios para o funcionamento da aplica√ß√£o. S√£o eles:

- ALB Security Group:
  - Entrada: permite tr√°fego HTTP (80) e SSH (22) de qualquer origem;
  - Sa√≠da: permite tr√°fego de qualquer protocolo para qualquer destino;

- EC2 Security Group:
  - Entrada: permite tr√°fego HTTP (80) proveniente do ALB Security Group e SSH (22) de qualquer origem;
  - Sa√≠da: permite tr√°fego de qualquer protocolo para qualquer destino;

- RDS Security Group:
  - Entrada: permite tr√°fego MySQL (3306) proveniente do EC2 Security Group;
  - Sa√≠da: permite tr√°fego de qualquer protocolo para qualquer destino;

- Locust Security Group:
  - Entrada: permite tr√°fego de qualquer protocolo para qualquer origem;
  - Sa√≠da: permite tr√°fego de qualquer protocolo para qualquer destino;

### IAM

Para garantir que as permiss√µes adequadas fossem assinaladas para as inst√¢ncias EC2, foi criado um IAM Role, com permiss√µes de escrita de logs, principalmente.

### RDS (Relational Database Service)

O RDS foi criado para hospedar o banco de dados MySQL. Portanto, sua engine √© `mysql` na vers√£o `8.0.33`, com `Multi-AZ` habilitado. Os backups s√£o retidos por 7 dias, e com uma janela de manuten√ß√£o semanal, √†s segundas-feiras, das 03:00 √†s 04:00, e de backup di√°rio, das 04:00 √†s 05:00. O RDS possui uma inst√¢ncia `db.t2.micro` com 20GB de armazenamento `gp2`. Para garantir a seguran√ßa do acesso ao banco de dados, os dados de usu√°rio e senha s√£o configurados em um arquivo `terraform.tfvars` e est√£o dispon√≠veis somente neles.

### ALB (Application Load Balancer)

O ALB foi criado para balancear a carga entre as inst√¢ncias EC2. Ele est√° dispon√≠vel publicamente na Internet. Ele tem um listener na porta 80 que encaminha o tr√°fego para o Target Group configurado (Inst√¢ncias EC2).

### ASG (Auto Scaling Group)

Mant√©m a quantidade de inst√¢ncias EC2 em 2, com um m√≠nimo de 2 e um m√°ximo de 6. A pol√≠tica de escalonamento √© configurada para expandir a quantidade de inst√¢ncias quando a utiliza√ß√£o de CPU atingir 70%, e reduzir a quantidade de inst√¢ncias quando a utiliza√ß√£o de CPU atingir 20%. A pol√≠tica de Health Check √© configurada para verificar a sa√∫de das inst√¢ncias a cada 5 minutos, com um tempo de espera de 1 minuto, e um limite de 1 falha consecutiva.

## Decis√µes t√©cnicas

- Para a aplica√ß√£o, configurada em Ubuntu, foi utilizado Elastic Compute Cloud (EC2);
- Para banco de dados, foi hospedado no Relational Database Service (RDS);
- Para a comunica√ß√£o entre os servi√ßos, foi utilizado o servi√ßo de Virtual Private Cloud (VPC);
- Para monitoramento de utiliza√ß√£o, foram implementadas m√©tricas e pol√≠ticas utilizando o servi√ßo de CloudWatch;
- Para balanceamento de carga, foi utilizado o servi√ßo de Application Load Balancer (ALB);
- Para garantir a prote√ß√£o da comunica√ß√£o entre os servi√ßos, foram criados _firewalls_, utilizando o servi√ßo de Security Groups;
- Para garantir o redirecionamento para somente inst√¢ncia saud√°veis, foram implementados Health Checks para o ALB;
- Para garantir a alta disponibilidade, foram criadas duas inst√¢ncias EC2 padr√£o, escal√°veis at√© seis, atrav√©s de uma Auto Scaling Group (ASG);
- Para garantir que n√£o haja concorr√™ncia nas opera√ß√µes do Terraform, foi utilizado o servi√ßo de Locking do DynamoDB, com armazenamento de estado no S3, garantindo o versionamento do c√≥digo;
- Para garantir a seguran√ßa das inst√¢ncias, foi criado um IAM Role, com somente as permiss√µes necess√°rias para a execu√ß√£o do script de instala√ß√£o e configura√ß√£o da aplica√ß√£o.

### A escolha de regi√£o

Com regi√µes de disponilibidade em todo o mundo, vem tamb√©m a necessidade de escolher uma regi√£o com requisitos que favore√ßa o desempenho e custo da aplica√ß√£o. Esses benef√≠cios s√£o obtidos atrav√©s de requisitos de:

- **Velocidade de Conex√£o** (Lat√™ncia):
  - Por ser uma aplica√ß√£o web que n√£o ser√° consumida como produto final, a lat√™ncia √© um fator opcional, pois n√£o √© um fator que influencia diretamente na experi√™ncia do usu√°rio. Por isso **n√£o foi um fator decisivo na escolha** da regi√£o;

- **Velocidade de Processamento**:
  - Devido aos dados a serem processados serem pequenos e simples, a velocidade de processamento n√£o impacta de forma relevante na aplica√ß√£o, portanto **n√£o foi um fator decisivo na escolha** da regi√£o;

- Disponibilidade de Servi√ßos:
  - A AWS possui uma grande variedade de servi√ßos, e a maioria deles est√° dispon√≠vel em todas as regi√µes, contudo existem restri√ß√µes. Por exemplo, o `t2.micro`, escolhida por ser a op√ß√£o _low-cost_ e _general purpose_ da AWS, est√° [dispon√≠vel somente em](https://aws.amazon.com/pt/about-aws/whats-new/2014/07/01/introducing-t2-the-new-low-cost-general-purpose-instance-type-for-amazon-ec2/):
    - `us-east-1` (N. Virginia);
    - `us-west-2` (Oregon);
    - `eu-west-1` (Ireland);
    - `ap-northeast-1` (Tokyo);
    - `ap-southeast-1` (Singapore);
    - `ap-southeast-2` (Sydney);
    - `sa-east-1` (S√£o Paulo);
  - H√° tamb√©m a necessidade de se descartar as regi√µes com outages mais frequentes, e como podemos ver nesta [_thread_ da YCombinator](https://news.ycombinator.com/item?id=13756082) (Aceleradora de Startups de Silicon Valley), a regi√£o `us-east-1` (N. Virginia) √© explicitamente n√£o recomendada, pois possui um hist√≥rico de outages mais frequentes, bem como equipamento ultrapassado. Ainda no mesmo t√≥pico, o site [AWSManiac](https://awsmaniac.com/aws-outages/) menciona as seguintes regi√µes como as de maior quantidade de outages da hist√≥ria da AWS, nesta ordem:
    - `us-east-1` (N. Virginia);
    - `ap-southeast-2` (Sydney);
    - `ap-northest-1` (Tokyo);
  - O site [StatusGator](https://statusgator.com/blog/is-north-virginia-aws-region-the-least-reliable-and-why/) oferece uma lista com as regi√µes com maior tempo de downtimes parcias em 2022, sendo, nesta ordem, as tr√™s piores:
    - `us-east-1` (N. Virginia);
    - `us-west-2` (Oregon);
    - `us-east-2` (Ohio);

- Custo de Servi√ßos:
  - O custo de servi√ßos √© um fator importante em qualquer aplica√ß√£o, e como o objetivo deste projeto √© criar uma aplica√ß√£o de baixo custo, √© necess√°rio escolher uma regi√£o que ofere√ßa os servi√ßos necess√°rios com o menor custo poss√≠vel. Os dados s√£o o site [ConcurrencyLabs](https://www.concurrencylabs.com/blog/choose-your-aws-region-wisely/), com dados extra√≠dos da AWS PriceList API. Portanto, da lista da `t2.micro` acima, podemos observar os seguintes pre√ßos (porcentagem de diferen√ßa em rela√ß√£o a `us-east-1`, a mais barata):
    - [0%] `us-east-1` (N. Virginia);
    - [0%] `us-west-2` (Oregon);
    - [11%] `eu-west-1` (Ireland);
    - [22%] `ap-northeast-1` (Tokyo);
    - [14%] `ap-southeast-1` (Singapore);
    - [26%] `ap-southeast-2` (Sydney);
    - [52%] `sa-east-1` (S√£o Paulo);

Baseado nesses requisitos, exclu√≠mos todas as regi√µes que n√£o possuem `t2.micro`. Em seguida, exclu√≠mos a regi√£o `us-east-1` (N. Virginia) pela imensa quantidade de outages. Exclu√≠mos `ap-southeast-2` (Sydney), `ap-northeast-1` (Tokyo) e `sa-east-1` (S√£o Paulo) por possu√≠rem uma grande diferen√ßa de custo em rela√ß√£o a `us-east-1` (N. Virginia). E por fim, exclu√≠mos `us-west-2` (Oregon) por possuir um hist√≥rico de outages, apesar de ser a segunda regi√£o mais barata. Com isso, ficamos em um empate entre `eu-west-1` (Ireland) e `ap-southeast-1` (Singapore), e como a regi√£o `eu-west-1` (Ireland) possui um custo 11% menor, foi a escolhida para hospedar a aplica√ß√£o.

### A escolha de monitoramento

O projeto utiliza o CloudWatch para monitorar as inst√¢ncias EC2 e o RDS. M√©tricas essenciais, como Utiliza√ß√£o de CPU e Contagem de Requisi√ß√µes da ALB, s√£o monitoradas. Para a utiliza√ß√£o de CPU, pol√≠ticas de escalonamento s√£o definidas em 70% para acionar a expans√£o e 20% para a redu√ß√£o, garantindo efici√™ncia financeira de recursos. Da mesma forma, a m√©trica de Contagem de Requisi√ß√µes da ALB √© configurada com limites 150 requisi√ß√µes, em um intervalo de espera de 5 minutos para evitar uma redu√ß√£o r√°pida de escala.

### A escolha de inst√¢ncias

O projeto utiliza a `t2.micro` para implanta√ß√£o de inst√¢ncias EC2. Por ser uma aplica√ß√£o CRUD, essa configura√ß√£o de baixo custo provisiona recursos suficientes para lidar com essas opera√ß√µes b√°sicas. Isso contribui para maximizar a efici√™ncia financeira do projeto.

### A escolha do banco de dados

O projeto utiliza a `db.t2.micro` para o RDS, que √© √≥tima para opera√ß√µes CRUD. Optamos pela implanta√ß√£o em Multi-Availability Zone para garantir alta disponibilidade, bem como toler√¢ncia a falhas. Por fim, optamos pelo General Purpose SSD (GP2) com capacidade de 20GB que d√° uma √≥tima margem para necessidades de armazenamento do projeto, que cobre uma poss√≠vel escalada de requisitos do projeto.

## Estimativa de custo de manuten√ß√£o mensal

Para realizar uma estimativa de custos, foi utilizado o [AWS Pricing Calculator](https://calculator.aws/#/). Os custos foram estimados para um per√≠odo de 1 m√™s, e os valores foram convertidos para Reais utilizando a cota√ß√£o do d√≥lar do dia 03/12/2023, de R$4,92, de acordo com o [Banco Central do Brasil](https://www.bcb.gov.br/conversao).

O valor total estimado para o per√≠odo de 1 m√™s foi de **$73.71**, ou seja, **R$362,65**. O resultado da calculadora de custo j√° com os valores de cada servi√ßo configurado est√° dispon√≠vel publicamente [neste link](https://calculator.aws/#/estimate?id=38b2eace6007c3130f5064e74299cf6d9eea6c94), ou no PDF dentro do reposit√≥rio, no caminho `/docs/AWS Pricing Calculator`. Abaixo, temos um resumo da configura√ß√£o utilizada para a estimativa de custos:

### Amazon Virtual Private Cloud (VPC)

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- VPC services: `Data Transfer`;
- Number of VPN Connections: `1`;
- Data Transfer Intra-region (GB): `1`;
- Data Transfer All other regions (GB): `1`.
- Data Transfer Out to Internet (GB): `1`;

### Amazon RDS for MySQL

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- Quantidade de inst√¢ncias: `1`;
- Tipo de inst√¢ncia: `db.t2.micro`;
- Utiliza√ß√£o: `On-Demand (100%)`;
- Deployment options: `Multi-AZ`;
- Storage: `General Purpose SSD (gp2)`;
- Storage (GB): `20`.

### Amazon EC2

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- Tipo de inst√¢ncia: `t2.micro`;
- Tenancy: `Shared`;
- Operating System: `Linux`;
- Workloads: `Daily spike traffic`;
- Workload (days): `Monday to Friday`;
- Baseline (instances): `2`;
- Peak (instances): `6`;
- Duration of peak (hours): `6`;
- Payment option: `EC2 Instance Savings Plans (1 Year, No Upfront)`.

### Elastic Load Balancing

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- Tipo de load balancer: `Application Load Balancer`;
- Features: `Load Balancer on Outposts`;
- N√∫mero de ALBs: `1`.

### Amazon Simple Storage Service (S3)

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- S3 Storage Class: `Standard`;
- Storage (GB): `0.01`;
- Requests: `10`;
- Data Returned by S3 Select (GB): `0.001`.
- Data Scanned by S3 Select (GB): `0.01`.

### Amazon DynamoDB

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- Features: `DynamoDB Data Import from Amazon S3 feature`;
- Source file size (GB): `0.01`;

### Amazon API Gateway

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- API Type: `REST API`;
- Request units: `millions`;
- Requests per month: `1`;

### Amazon CloudWatch

Par√¢metros:

- Regi√£o: `eu-west-1` (Ireland);
- Number of metrics: `2`;
- Number of Standard Resolution Alarm Metrics: `2`;

## Custo real utilizando o Locust para testes de carga

Para realizar os testes de carga, foi utilizado o Locust, uma ferramenta de c√≥digo aberto para testes de carga. Sua utiliza√ß√£o foi t√£o somente acessar o endere√ßo no navegador e configurar um teste de carga de 250 usu√°rios, com 50 usu√°rios por segundo, e um tempo de execu√ß√£o de 10 minutos. O resultado do teste pode ser visto nas imagens abaixo:

![Locust 1](./docs/Locust_chart.png)

![Locust 2](./docs/Locust_current_ratio.png)

Isso resulta na execu√ß√£o da Policy estabelecida para o ALB, que pode ser vista no dashboard depois de pouco tempo de execu√ß√£o do teste:

![Dashboard 1](./docs/AWS_dashboard_before.jpeg)

Depois do fim do teste carga, podemos ver que foi bem sucedido o downscaling das inst√¢ncias EC2:

![Dashboard 2](./docs/AWS_dashboard_after.png)

Para calcular o custo real de manuten√ß√£o mensal, foi utilizado o [AWS Billing and Cost Management](https://console.aws.amazon.com/billing/home?#/).

Como forma de validar a estimativa da Calculadora de Custos AWS, levamos em conta o tempo em que o teste carga rodou (10 minutos), com uma taxa de swarm do Locust de aproximadamente 122 RPS. Assim, observamos o painel de custos da regi√£o `eu-west-1` (Ireland), que pode ser visto abaixo:

![Billing 1](./docs/AWS_dashboard_price.png)

Contudo √© necess√°rio deduzir os custos n√£o relacionados ao swarm do Locust, neste caso os valores contornados em vermelho na imagem abaixo:

![Billing 2](./docs/AWS_dashboard_deduction.png)

Portanto, do total de **$3.51**, devem ser descontados:

- 10 minutos representam aproximadamente 1.11% de 15 horas, portanto 11% sobre $0.54, resulta em desconto de **$0,48**;
- 10 minutos representam aproximadamente 0.52% de 32 horas, portanto 0.52% sobre $1.54, resulta em desconto de **$1.53**;
- 10 minutos representam aproximadamente 0.56% de 30 horas, portanto 0.56% sobre $0.39, resulta em desconto de **$0.389**.

Assim, o custo real de manuten√ß√£o em 10 minutos de teste de carga √© de **$1.111**. Vale ressaltar que esse √© um fluxo muito at√≠pico e que representa o equivalente ao fluxo de 1 dia da aplica√ß√£o no mundo real. Assim, podemos extrapolar isso para a aplica√ß√£o rodando todos os dias da semana, o custo real de manuten√ß√£o mensal √© de **$33,33**, ou seja, **R$163,99**.
